## CS4641 Customer Data Segmentation Analysis Project

### FINAL PROJECT REPORT
Please See in our Colab Here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/andrewbhennessy/CS4641-Customer-Segmentation-Analysis/blob/main/Final_Project_Report.ipynb)

The Timestamped document available in our main branch is here: [![Made withJupyter](https://img.shields.io/badge/Made%20with-Jupyter-orange?style=for-the-badge&logo=Jupyter)](https://github.com/andrewbhennessy/CS4641-Customer-Segmentation-Analysis/blob/main/Final_Project_Report.ipynb)


### Introduction:

The COVID-19 pandemic has greatly affected the way all companies advertise for their businesses. Now more than ever, online presence and advertising are necessary to attract customers. While each customer is unique, a similar group of customers can be identified based on their purchase history. By grouping customers together based on recency, frequency, and monetary value we can create specific advertisements and incentives to maximize the revenue generated by a company. This is almost always more successful than creating generalized incentives and other types of advertisements aimed at the entire population.

### Problem Definition:

Our project will use customer spending datasets to group customers together based on 3 features: recency, frequency, and monetary value. This will allow advertising to become specialized to each cluster. With this, companies can target these groups and make advertisements and incentives specifically aimed at each of them. By analyzing the spending habits in each cluster, companies can more efficiently allocate their advertising funds.

### Methods:

We will be testing K-means, DBSCAN, and GMM to specify our groups. Using K-means method, points are assigned to their nearest centroid based on their Euclidean distance. The points assigned to the same centroid form a cluster. After the clusters are formed, a new centroid is calculated for each cluster by taking the mean of the cluster. This is repeated until the centroids can no longer move any further. K-means will include all data points in its clustering groups. The Elbow method can be used to find the optimal number of clusters. A disadvantage to K-means is that the cluster groups will all be more or less circular, whereas other forms of clustering can create irregular-shaped cluster groups. In addition, K-means is sensitive to outliers since new centroids are calculated every iteration and extreme values can easily affect the location of centroids.

DBSCAN is another performative clustering algorithm that categorizes nearby points into same cluster. It takes two parameters which are known as epsilon and minimum number of points. Epsilon refers to the required distance between two points in order for them to be classified as the same cluster. Minimum number of points is required number of data points to form a cluster. Typically, minimum number of points must be more than the number of dimensions in a data set and the higher dimensions in a data set, the more minimum number of points required. In contrast to K-means, DBSCAN doesn’t require to input the number of cluster and is capable of handling outliers. In fact, it will produce as many clusters as needed depending on the values of parameters. A weakness of DBSCAN is that it struggles to appropriately separate a data set if the data set contains many groups with similar density.

Last method we will be testing is Gaussian Mixture Models (GMM). While K-means is only capable of clustering in circular fashion, GMM can handle oblong clusters. GMM groups a data set in a similar way as K-means but GMM takes variance into account since GMM involves mixture of multiple Gaussian distributions. Also, GMM is competent in performing soft classification which allows to reveal not only the cluster a data point belongs to but also the probabilities of all potential clusters it may belong to.

### Potential Results:

Classify customer population into some number of specific groups (clusters). Companies can then create advertisements aiming towards attracting the different categories of customers. 


### Discussion

Prior to applying any clustering methods, we underwent multiple data cleaning processes, calculations, and outlier treatment to prepare our data for a new powerful method called RFM segmentation. RFM segmentation allowed our data set to be finalized so that each data point (customer) has three features: recency, frequency and monetary. Using these three features, we applied K-means clustering analysis to group each customer into a certain number of clusters. In order to test for the optimal number of clusters, we visualized silhouette coefficients for over a range from 2 to 15 clusters as well as the sum of squared distances for elbow test. After analyzing two graphs, we figured the optimal number of clusters for our dataset to be 8 with a silhouette coefficient around 0.36. Using these values, we tested K-means with 8 clusters and obtained a visualization as well as the average feature values for each cluster as shown in the results section. The average values for each feature are not normalized so the magnitudes of each average are independent from other features’ averages. By examining the values of averages, we can characterize each cluster as below:

Cluster 0: Inactive, One time, Low-spending customers (Worst)

Cluster 1: New, One time, Low-spending customers

Cluster 2: Fairly recent, Moderately Frequent, High-spending customers

Cluster 3: Inactive, Moderately Frequent, Moderate-spending customers

Cluster 4: Fairly recent, Frequent, High-spending customers (Best)

Cluster 5: Fairly recent, Frequent, Moderate-spending customers

Cluster 6: Fairly recent, one time, Low-spending customers

Cluster 7: New, Moderately Frequent, Moderate-spending customers

The figure for K-means cluster magnitudes suggests that large portion of customers in our data set belongs to cluster 3, which depicts that many customers are no longer active in recent time and spent moderate amount of money fairly many times. On the other hand, cluster 4, the best group of customers for the company unfortunately covers the lowest portion of our data set, so better marketing techniques are required to be implemented in order to increase the revenue.

After applying K-means, we tested another clustering method, DBSCAN. With epsilon value of 0.45 and minimum number of points of 4, DBSCAN ultimately produced 12 clusters. Unfortunately, the visualization of these clusters suggests that this method did not produce a pleasant outcome since the clusters seemed to be formed based off of only frequency score. We suspect this failure is due to our data set having too many groups of customers with similar densities. Since DBSCAN uses densities to classify each data point, it will perform well with a data set that has a large gap of densities among the clusters.

Last method we tested was GMM. Similar to K-means, we used 8 clusters to visualize how clusters are formed from this method. By looking at the average feature scores for each cluster we can categorized each cluster as such:

Cluster 0: Fairly recent, Moderately Frequent, Low-spending customers

Cluster 1: Fairly recent, Moderately Frequent, High-spending customers

Cluster 2: New, Moderately Frequent, Low-spending customers

Cluster 3: Fairly recent, One time, Low-spending customers(Worst)

Cluster 4: Fairly recent, Frequent, High-spending customers (Best)

Cluster 5: New, Moderately Frequent, Low-spending customers

Cluster 6: Fairly recent, Frequent, Moderate-spending customers

Cluster 7: Fairly recent, Moderately Frequent, Low-spending customers

Although it was hardly visible in the graph, we figured GMM did not optimally partition the data. As seen above, there are many clusters that share similar average recency score; most clusters referred to fairly recent customers and had lower range of average recency score compared to the clusters made from K-means. This faulty performance of GMM on our data set is potentially due to the flexibility of GMM to account for variances. Since we are only interested in completely classifying our data, GMM might have malfunctioned by attempting to find probabilities of each data point belonging other clusters. Overall, we concluded that K-means offered the most optimal clusters, meaning each cluster had the most distinctive characteristics compared to other clusters.

Using the clusters produced from the most performative method, K-means, we can organize a better marketing campaigns for each type of customers. For instance, a company can endeavor to regain old, inactive customers such as cluster 0 and 3 by examining their past transaction data to find their preferences and consistently introducing them with new deals and products of their interests. For those who are active and loyal but spend low amount such as cluster 5 and 7, the company needs to ensure they feel comfortable spending more while remaining active and loyal. Therefore, they should never feel forced to buy other pricy products but instead, the company should naturally upsell their spending by offering them with rewards for purchasing expensive products. Cluster 1 and 6 represent a group of customers who are new and transacting with the company for the first time. It is critical for the company to leave a pleasant first impression to those customers in order to attract as many new customers as possible. Welcoming them for their first purchases with coupons can make them feel valued and increase the chance of converting them to regular shoppers. Another marketing tip to attract more new customers is to encourage current shoppers to advertise the company on their personal social networks by incentivizing with rewards. Lastly, cluster 2 and 4 refer to a group of best customers who heavily contribute to the company’s overall revenue. The main target for this group is to encourage them to remain as frequent shoppers by optimizing their experiences and showing appreciation for all their purchases. Also, their previous purchase histories should be thoroughly analyzed to actively communicate with them by sending personalized messages, which can make them feel appreciated even more.


### Conclusion

Due to COVID-19 pandemic, there is a significant increase of online shoppers. Therefore, it is crucial for many companies to revisit their advertising techniques to thrive prosperous businesses during this global crisis. Luckily, online commerce facilitates for a company to easily access their customers’ transaction data, which can be used as a data set for many classification methods that group each unique individual to various clusters. There are many methods of classification, but our project incorporated three different algorithms: K-means, DBSCAN, and GMM. Although we reported that K-means was the best method for our data set, this may vary depending on the data set’s size, density, number of features, etc. Therefore, it is highly recommended to attempt many different methods to figure out the best performative method. After most effectively grouping customers into different clusters, a company can scrutinize the characteristics of each cluster and prepare the most suited marketing campaign for each targeted cluster. By doing so, a company will be able to overcome this global pandemic crisis and earn a tremendous benefit in terms of increase in revenue and number of customers.

### Final Project Video

[Final Project Video](https://youtu.be/Pov6BMXMqO4)

### References

1. Hossain, Shahadat. “Customer Segmentation Using Centroid Based and Density Based Clustering Algorithms.” Customer Segmentation Using Centroid Based and Density Based Clustering Algorithms - IEEE Conference Publication, 1 Feb. 2018, [ieeexplore.ieee.org/document/8275249.](ieeexplore.ieee.org/document/8275249.)

2. Modukuru, Pranay. “Customer Segmentation and Acquisition Using Machine Learning.” Medium, Towards Data Science, 19 Apr. 2020, [towardsdatascience.com/customer-segmentation-and-acquisition-using-machine-learning-a219ce0ec139.](towardsdatascience.com/customer-segmentation-and-acquisition-using-machine-learning-a219ce0ec139.) 

3. Sekhar, Babu B, and Prasanna P Lakshmi. “Customer Data Clustering Using Density Based Algorithm.” Research Gate, International Journal of Engineering &amp; Technology, May 2018, [www.researchgate.net/publication/325881992_Customer_Data_Clustering_using_Density_based_algorithm.](www.researchgate.net/publication/325881992_Customer_Data_Clustering_using_Density_based_algorithm.)
